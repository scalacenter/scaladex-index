<div class="announce instapaper_body md" data-path="README.md" id="readme">
 <article class="markdown-body entry-content" itemprop="text">
  <h1><a id="user-content-spark-netflow" class="anchor" href="https://github.com/sadikovi/spark-netflow#spark-netflow" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>spark-netflow</h1> 
  <p>A library for reading NetFlow files from <a href="http://spark.apache.org/docs/latest/sql-programming-guide.html" target="_blank">Spark SQL</a>.</p> 
  <p><a href="https://travis-ci.org/sadikovi/spark-netflow" target="_blank"><img src="https://camo.githubusercontent.com/6321652a6918b148aa886bfeaaea14b10773f503/68747470733a2f2f7472617669732d63692e6f72672f736164696b6f76692f737061726b2d6e6574666c6f772e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/sadikovi/spark-netflow.svg?branch=master" style="max-width:100%;"></a> <a href="https://codecov.io/gh/sadikovi/spark-netflow" target="_blank"><img src="https://camo.githubusercontent.com/73857996eab52a83101af3f52adbae81c7315115/68747470733a2f2f636f6465636f762e696f2f67682f736164696b6f76692f737061726b2d6e6574666c6f772f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="codecov" data-canonical-src="https://codecov.io/gh/sadikovi/spark-netflow/branch/master/graph/badge.svg" style="max-width:100%;"></a></p> 
  <h2><a id="user-content-requirements" class="anchor" href="https://github.com/sadikovi/spark-netflow#requirements" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Requirements</h2> 
  <table> 
   <thead> 
    <tr> 
     <th>Spark version</th> 
     <th>spark-netflow latest version</th> 
    </tr> 
   </thead> 
   <tbody> 
    <tr> 
     <td>1.4.x</td> 
     <td><a href="http://spark-packages.org/package/sadikovi/spark-netflow" target="_blank">1.3.1</a></td> 
    </tr> 
    <tr> 
     <td>1.5.x</td> 
     <td><a href="http://spark-packages.org/package/sadikovi/spark-netflow" target="_blank">1.3.1</a></td> 
    </tr> 
    <tr> 
     <td>1.6.x</td> 
     <td><a href="http://spark-packages.org/package/sadikovi/spark-netflow" target="_blank">1.3.1</a></td> 
    </tr> 
    <tr> 
     <td>2.0.x</td> 
     <td><a href="http://spark-packages.org/package/sadikovi/spark-netflow" target="_blank">2.0.2</a></td> 
    </tr> 
    <tr> 
     <td>2.1.x</td> 
     <td><a href="http://spark-packages.org/package/sadikovi/spark-netflow" target="_blank">2.0.2</a></td> 
    </tr>
   </tbody>
  </table> 
  <blockquote> 
   <p>Documentation reflects changes in master branch, for documentation on a specific version, please select corresponding version tag or branch.</p> 
  </blockquote> 
  <h2><a id="user-content-linking" class="anchor" href="https://github.com/sadikovi/spark-netflow#linking" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Linking</h2> 
  <p>The spark-netflow library can be added to Spark by using the <code>--packages</code> command line option. For example, run this to include it when starting the spark shell:</p> 
  <div class="highlight highlight-source-shell">
   <pre> <span class="pl-smi">$SPARK_HOME</span>/bin/spark-shell --packages com.github.sadikovi:spark-netflow_2.11:2.0.2</pre>
  </div> 
  <p>Change to <code>com.github.sadikovi:spark-netflow_2.10:2.0.2</code> for Scala 2.10.x</p> 
  <h2><a id="user-content-features" class="anchor" href="https://github.com/sadikovi/spark-netflow#features" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Features</h2> 
  <ul> 
   <li>Column pruning</li> 
   <li>Predicate pushdown to the NetFlow file</li> 
   <li>Auto statistics based on file header information</li> 
   <li>Fields conversion (IP addresses, protocol, etc.)</li> 
   <li>NetFlow version 5 support (<a href="https://github.com/sadikovi/spark-netflow/blob/master/docs/NETFLOW_V5.md" target="_blank">list of columns</a>)</li> 
   <li>NetFlow version 7 support (<a href="https://github.com/sadikovi/spark-netflow/blob/master/docs/NETFLOW_V7.md" target="_blank">list of columns</a>)</li> 
   <li>Reading files from local file system and HDFS</li> 
  </ul> 
  <h3><a id="user-content-options" class="anchor" href="https://github.com/sadikovi/spark-netflow#options" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Options</h3> 
  <p>Currently supported options:</p> 
  <table> 
   <thead> 
    <tr> 
     <th>Name</th> 
     <th align="center">Example</th> 
     <th>Description</th> 
    </tr> 
   </thead> 
   <tbody> 
    <tr> 
     <td><code>version</code></td> 
     <td align="center"><em>5, 7</em></td> 
     <td>version to use when parsing NetFlow files, can be your own version provider as class name. Optional, by default will resolve from provided files</td> 
    </tr> 
    <tr> 
     <td><code>buffer</code></td> 
     <td align="center"><em>1024, 32Kb, 3Mb, etc</em></td> 
     <td>buffer size for NetFlow compressed stream (default <code>1Mb</code>)</td> 
    </tr> 
    <tr> 
     <td><code>stringify</code></td> 
     <td align="center"><em>true, false</em></td> 
     <td>convert certain supported fields (e.g. IP, protocol) into human-readable format. If performance is essential consider disabling feature (default <code>true</code>)</td> 
    </tr> 
    <tr> 
     <td><code>predicate-pushdown</code></td> 
     <td align="center"><em>true, false</em></td> 
     <td>enable predicate pushdown at NetFlow library level (default <code>true</code>)</td> 
    </tr>
   </tbody>
  </table> 
  <h3><a id="user-content-dealing-with-corrupt-files" class="anchor" href="https://github.com/sadikovi/spark-netflow#dealing-with-corrupt-files" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Dealing with corrupt files</h3> 
  <p>Package supports Spark option <code>spark.files.ignoreCorruptFiles</code>. When set to <code>true</code>, corrupt files are ignored (corrupt header, wrong format) or partially read (corrupt data block in a middle of a file). By default, option is set to <code>false</code>, meaning exception will be raised when such file is encountered, this behaviour is similar to Spark.</p> 
  <h2><a id="user-content-example" class="anchor" href="https://github.com/sadikovi/spark-netflow#example" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Example</h2> 
  <h3><a id="user-content-scala-api" class="anchor" href="https://github.com/sadikovi/spark-netflow#scala-api" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Scala API</h3> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-c"><span class="pl-c">//</span> You can provide only format, package will infer version from provided files, or you can enforce</span>
<span class="pl-c"><span class="pl-c">//</span> version of the files with `version` option.</span>
<span class="pl-k">val</span> <span class="pl-en">df</span> <span class="pl-k">=</span> spark.read.format(<span class="pl-s"><span class="pl-pds">"</span>com.github.sadikovi.spark.netflow<span class="pl-pds">"</span></span>).load(<span class="pl-s"><span class="pl-pds">"</span>...<span class="pl-pds">"</span></span>)

<span class="pl-c"><span class="pl-c">//</span> You can read files from local file system or HDFS</span>
<span class="pl-k">val</span> <span class="pl-en">df</span> <span class="pl-k">=</span> spark.read.format(<span class="pl-s"><span class="pl-pds">"</span>com.github.sadikovi.spark.netflow<span class="pl-pds">"</span></span>).
  option(<span class="pl-s"><span class="pl-pds">"</span>version<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>5<span class="pl-pds">"</span></span>).load(<span class="pl-s"><span class="pl-pds">"</span>file:/...<span class="pl-pds">"</span></span>).
  select(<span class="pl-s"><span class="pl-pds">"</span>srcip<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>dstip<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>packets<span class="pl-pds">"</span></span>)

<span class="pl-c"><span class="pl-c">//</span> You can also specify buffer size when reading compressed NetFlow files</span>
<span class="pl-k">val</span> <span class="pl-en">df</span> <span class="pl-k">=</span> spark.read.format(<span class="pl-s"><span class="pl-pds">"</span>com.github.sadikovi.spark.netflow<span class="pl-pds">"</span></span>).
  option(<span class="pl-s"><span class="pl-pds">"</span>version<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>5<span class="pl-pds">"</span></span>).option(<span class="pl-s"><span class="pl-pds">"</span>buffer<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>50Mb<span class="pl-pds">"</span></span>).load(<span class="pl-s"><span class="pl-pds">"</span>hdfs://sandbox:8020/tmp/...<span class="pl-pds">"</span></span>)</pre>
  </div> 
  <p>Alternatively you can use shortcuts for NetFlow files</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">import</span> <span class="pl-v">com.github.sadikovi.spark.netflow.</span><span class="pl-v">_</span>

<span class="pl-c"><span class="pl-c">//</span> this will read version 5 with default buffer size</span>
<span class="pl-k">val</span> <span class="pl-en">df</span> <span class="pl-k">=</span> spark.read.netflow5(<span class="pl-s"><span class="pl-pds">"</span>hdfs:/...<span class="pl-pds">"</span></span>)

<span class="pl-c"><span class="pl-c">//</span> this will read version 7 without fields conversion</span>
<span class="pl-k">val</span> <span class="pl-en">df</span> <span class="pl-k">=</span> spark.read.option(<span class="pl-s"><span class="pl-pds">"</span>stringify<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>false<span class="pl-pds">"</span></span>).netflow7(<span class="pl-s"><span class="pl-pds">"</span>file:/...<span class="pl-pds">"</span></span>)</pre>
  </div> 
  <h3><a id="user-content-python-api" class="anchor" href="https://github.com/sadikovi/spark-netflow#python-api" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Python API</h3> 
  <div class="highlight highlight-source-python">
   <pre>df <span class="pl-k">=</span> spark.read.format(<span class="pl-s"><span class="pl-pds">"</span>com.github.sadikovi.spark.netflow<span class="pl-pds">"</span></span>).option(<span class="pl-s"><span class="pl-pds">"</span>version<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>5<span class="pl-pds">"</span></span>).
  load(<span class="pl-s"><span class="pl-pds">"</span>file:/...<span class="pl-pds">"</span></span>).select(<span class="pl-s"><span class="pl-pds">"</span>srcip<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>srcport<span class="pl-pds">"</span></span>)

res <span class="pl-k">=</span> df.where(<span class="pl-s"><span class="pl-pds">"</span>srcip &gt; 10<span class="pl-pds">"</span></span>)</pre>
  </div> 
  <h3><a id="user-content-sql-api" class="anchor" href="https://github.com/sadikovi/spark-netflow#sql-api" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>SQL API</h3> 
  <div class="highlight highlight-source-sql">
   <pre>CREATE TEMPORARY TABLE ips
USING <span class="pl-c1">com</span>.<span class="pl-c1">github</span>.<span class="pl-c1">sadikovi</span>.<span class="pl-c1">spark</span>.netflow
OPTIONS (<span class="pl-k">path</span> <span class="pl-s"><span class="pl-pds">"</span>file:/...<span class="pl-pds">"</span></span>, version <span class="pl-s"><span class="pl-pds">"</span>5<span class="pl-pds">"</span></span>);

<span class="pl-k">SELECT</span> srcip, dstip, srcport, dstport <span class="pl-k">FROM</span> ips <span class="pl-k">LIMIT</span> <span class="pl-c1">10</span>;</pre>
  </div> 
  <h2><a id="user-content-building-from-source" class="anchor" href="https://github.com/sadikovi/spark-netflow#building-from-source" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Building From Source</h2> 
  <p>This library is built using <code>sbt</code>, to build a JAR file simply run <code>sbt package</code> from project root. To build jars for Scala 2.10.x and 2.11.x run <code>sbt +package</code>.</p> 
  <h2><a id="user-content-testing" class="anchor" href="https://github.com/sadikovi/spark-netflow#testing" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Testing</h2> 
  <p>Run <code>sbt test</code> from project root.</p> 
  <h2><a id="user-content-running-benchmark" class="anchor" href="https://github.com/sadikovi/spark-netflow#running-benchmark" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Running benchmark</h2> 
  <p>Run <code>sbt package</code> to package project, next run <code>spark-submit</code> with following options:</p> 
  <div class="highlight highlight-source-shell">
   <pre>$ spark-submit --class com.github.sadikovi.spark.benchmark.NetFlowReadBenchmark \
  target/scala-2.11/spark-netflow_2.11-2.0.2.jar \
  --iterations 5 \
  --files <span class="pl-s"><span class="pl-pds">'</span>file:/Users/sadikovi/developer/spark-netflow/temp/ftn/0[1,2,3]/ft*<span class="pl-pds">'</span></span> \
  --version 5</pre>
  </div> 
  <p>Latest benchmarks:</p> 
  <pre><code>- Iterations: 5
- Files: file:/Users/sadikovi/developer/spark-netflow/temp/ftn/0[1,2,3]/ft*
- Version: 5
Running benchmark: NetFlow full scan
  Running case: Scan, stringify = F
  Running case: Scan, stringify = T                                             

Intel(R) Core(TM) i5-4258U CPU @ 2.40GHz
NetFlow full scan:                  Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative
-------------------------------------------------------------------------------------------
Scan, stringify = F                       364 /  462       2748.0       36389.9       1.0X
Scan, stringify = T                       923 /  935       1082.9       92347.8       0.4X

Running benchmark: NetFlow predicate scan
  Running case: Predicate pushdown = F, high
  Running case: Predicate pushdown = T, high                                    
  Running case: Predicate pushdown = F, low                                     
  Running case: Predicate pushdown = T, low                                     

Intel(R) Core(TM) i5-4258U CPU @ 2.40GHz
NetFlow predicate scan:             Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative
-------------------------------------------------------------------------------------------
Predicate pushdown = F, high             1009 / 1094        991.2      100892.6       1.0X
Predicate pushdown = T, high             1056 / 2029        947.2      105570.7       1.0X
Predicate pushdown = F, low               766 /  833       1304.9       76633.3       1.3X
Predicate pushdown = T, low               175 /  181       5709.3       17515.4       5.8X

Running benchmark: NetFlow aggregated report
  Running case: Aggregated report

Intel(R) Core(TM) i5-4258U CPU @ 2.40GHz
NetFlow aggregated report:          Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative
-------------------------------------------------------------------------------------------
Aggregated report                        1362 / 2242        734.3      136183.3       1.0X
</code></pre> 
  <h2><a id="user-content-using-netflowlib-library-separately" class="anchor" href="https://github.com/sadikovi/spark-netflow#using-netflowlib-library-separately" aria-hidden="true" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Using <code>netflowlib</code> library separately</h2> 
  <p>You can use <code>netflowlib</code> without using <code>spark-netflow</code> package. Here some basic concepts and examples:</p> 
  <ul> 
   <li><code>com.github.sadikovi.netflowlib.predicate.Columns.*</code> all available column types in the library, check out <code>com.github.sadikovi.netflowlib.version.*</code> classes to see what columns are already defined for a specific NetFlow format.</li> 
   <li><code>com.github.sadikovi.netflowlib.predicate.FilterApi</code> utility class to create predicates for NetFlow file</li> 
   <li><code>com.github.sadikovi.netflowlib.statistics.StatisticsTypes</code> statistics that you can use to reduce boundaries of filter or allow filter to be evaluated before scanning the file. For example, library creates statistics on time, so time filter can be resolved upfront</li> 
   <li><code>com.github.sadikovi.netflowlib.NetFlowReader</code> main entry to work with NetFlow file, gives access to file header and iterator of rows, allows to pass additional predicate and statistics</li> 
   <li><code>com.github.sadikovi.netflowlib.NetFlowHeader</code> header information can be accessed using this class from <code>NetFlowReader.getHeader()</code>, see class for more information on flags available</li> 
  </ul> 
  <p>Note that library has only one external dependency on <code>io.netty.buffer.ByteBuf</code> buffers, which could be replaced with standard Java buffer functionality, but since it was built for being used as part of a spark-package, this dependency comes with Spark.</p> 
  <p>Here is the general usage pattern:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">import</span> <span class="pl-v">com.github.sadikovi.netflowlib.</span><span class="pl-v">NetFlowReader</span>
<span class="pl-k">import</span> <span class="pl-v">com.github.sadikovi.netflowlib.version.</span><span class="pl-v">NetFlowV5</span>

<span class="pl-c"><span class="pl-c">//</span> Create input stream by opening NetFlow file, e.g. `fs.open(hadoopFile)`</span>
<span class="pl-k">val</span> <span class="pl-en">stm</span><span class="pl-k">:</span> <span class="pl-en">DataInputStream</span> <span class="pl-k">=</span> ...
<span class="pl-c"><span class="pl-c">//</span> Prepare reader based on input stream and buffer size, you can use</span>
<span class="pl-c"><span class="pl-c">//</span> overloaded alternative with default buffer size</span>
<span class="pl-k">val</span> <span class="pl-en">reader</span> <span class="pl-k">=</span> <span class="pl-en">NetFlowReader</span>.prepareReader(stm, <span class="pl-c1">10000</span>)
<span class="pl-c"><span class="pl-c">//</span> Check out header, optional</span>
<span class="pl-k">val</span> <span class="pl-en">header</span> <span class="pl-k">=</span> reader.getHeader()
<span class="pl-c"><span class="pl-c">//</span> Actual NetFlow version of the file</span>
<span class="pl-k">val</span> <span class="pl-en">actualVersion</span> <span class="pl-k">=</span> header.getFlowVersion()
<span class="pl-c"><span class="pl-c">//</span> Whether or not file is compressed</span>
<span class="pl-k">val</span> <span class="pl-en">isCompressed</span> <span class="pl-k">=</span> header.isCompressed()

<span class="pl-c"><span class="pl-c">//</span> This is list of fields that will be returned in iterator as values in</span>
<span class="pl-c"><span class="pl-c">//</span> array (same order)</span>
<span class="pl-k">val</span> <span class="pl-en">fields</span> <span class="pl-k">=</span> <span class="pl-en">Array</span>(
  <span class="pl-en">NetFlowV5</span>.<span class="pl-en">FIELD_UNIX_SECS</span>,
  <span class="pl-en">NetFlowV5</span>.<span class="pl-en">FIELD_SRCADDR</span>,
  <span class="pl-en">NetFlowV5</span>.<span class="pl-en">FIELD_DSTADDR</span>,
  <span class="pl-en">NetFlowV5</span>.<span class="pl-en">FIELD_SRCPORT</span>,
  <span class="pl-en">NetFlowV5</span>.<span class="pl-en">FIELD_DSTPORT</span>
)

<span class="pl-c"><span class="pl-c">//</span> Build record buffer and iterator that you can use to get values.</span>
<span class="pl-c"><span class="pl-c">//</span> Note that you can also use set of filters, if you want to get</span>
<span class="pl-c"><span class="pl-c">//</span> particular records</span>
<span class="pl-k">val</span> <span class="pl-en">recordBuffer</span> <span class="pl-k">=</span> reader.prepareRecordBuffer(fields)
<span class="pl-k">val</span> <span class="pl-en">iter</span> <span class="pl-k">=</span> recordBuffer.iterator()

<span class="pl-k">while</span> (iter.hasNext) {
  <span class="pl-c"><span class="pl-c">//</span> print every row with values</span>
  println(iter.next)
}</pre>
  </div> 
  <p>Here is an example of using predicate to keep certain records:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">import</span> <span class="pl-v">com.github.sadikovi.netflowlib.predicate.</span><span class="pl-v">FilterApi</span>
<span class="pl-k">val</span> <span class="pl-en">predicate</span> <span class="pl-k">=</span> <span class="pl-en">FilterApi</span>.and(
  <span class="pl-en">FilterApi</span>.eq(<span class="pl-en">NetFlowV5</span>.<span class="pl-en">FIELD_SRCPORT</span>, <span class="pl-c1">123</span>),
  <span class="pl-en">FilterApi</span>.eq(<span class="pl-en">NetFlowV5</span>.<span class="pl-en">FIELD_DSTPORT</span>, <span class="pl-c1">456</span>)
)

...
<span class="pl-k">val</span> <span class="pl-en">recordBuffer</span> <span class="pl-k">=</span> reader.prepareRecordBuffer(fields, predicate)</pre>
  </div> 
 </article>
</div>
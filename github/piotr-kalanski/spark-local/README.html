<div class="announce instapaper_body md" data-path="README.md" id="readme">
 <article class="markdown-body entry-content" itemprop="text">
  <h1><a href="https://github.com/piotr-kalanski/spark-local#spark-local" aria-hidden="true" class="anchor" id="user-content-spark-local" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>spark-local</h1> 
  <p>API enabling switching between Spark execution engine and local implementation based on Scala collections.</p> 
  <p><a href="https://api.travis-ci.org/piotr-kalanski/spark-local.png?branch=development" target="_blank"><img src="https://camo.githubusercontent.com/5dc41fc21f51c3269e74d348155a1a99466b8ffa/68747470733a2f2f6170692e7472617669732d63692e6f72672f70696f74722d6b616c616e736b692f737061726b2d6c6f63616c2e706e673f6272616e63683d646576656c6f706d656e74" alt="Build Status" data-canonical-src="https://api.travis-ci.org/piotr-kalanski/spark-local.png?branch=development" style="max-width:100%;"></a> <a href="http://codecov.io/github/piotr-kalanski/spark-local/coverage.svg?branch=development" target="_blank"><img src="https://camo.githubusercontent.com/82f90ca2e3285300191b8021bdc784114b4fdb21/687474703a2f2f636f6465636f762e696f2f6769746875622f70696f74722d6b616c616e736b692f737061726b2d6c6f63616c2f636f7665726167652e7376673f6272616e63683d646576656c6f706d656e74" alt="codecov.io" data-canonical-src="http://codecov.io/github/piotr-kalanski/spark-local/coverage.svg?branch=development" style="max-width:100%;"></a> <a href="http://search.maven.org/#search%7Cga%7C1%7Ca%3A%22spark-local_2.11%22" target="_blank"><img src="https://camo.githubusercontent.com/7cd9df930e005bb61eb9cef263dea13210cf5d4f/68747470733a2f2f696d672e736869656c64732e696f2f6d6176656e2d63656e7472616c2f762f636f6d2e6769746875622e70696f74722d6b616c616e736b692f737061726b2d6c6f63616c5f322e31312e7376673f6c6162656c3d6c617465737425323072656c65617365" data-canonical-src="https://img.shields.io/maven-central/v/com.github.piotr-kalanski/spark-local_2.11.svg?label=latest%20release" style="max-width:100%;"></a> <a href="https://waffle.io/piotr-kalanski/spark-local" target="_blank"><img src="https://camo.githubusercontent.com/3e5ed867b27859f480b03176cf3a56000ca1975a/68747470733a2f2f62616467652e776166666c652e696f2f70696f74722d6b616c616e736b692f737061726b2d6c6f63616c2e706e673f6c6162656c3d5265616479" alt="Stories in Ready" data-canonical-src="https://badge.waffle.io/piotr-kalanski/spark-local.png?label=Ready" style="max-width:100%;"></a> <a href="http://www.apache.org/licenses/LICENSE-2.0.txt" target="_blank"><img src="https://camo.githubusercontent.com/17d81d2643f6ee5fcc87c8f7f74588da4b5e6bb7/687474703a2f2f696d672e736869656c64732e696f2f3a6c6963656e73652d417061636865253230322d7265642e737667" alt="License" data-canonical-src="http://img.shields.io/:license-Apache%202-red.svg" style="max-width:100%;"></a></p> 
  <h1><a href="https://github.com/piotr-kalanski/spark-local#table-of-contents" aria-hidden="true" class="anchor" id="user-content-table-of-contents" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Table of contents</h1> 
  <ul> 
   <li><a href="https://github.com/piotr-kalanski/spark-local#goals" target="_blank">Goals</a></li> 
   <li><a href="https://github.com/piotr-kalanski/spark-local#getting-started" target="_blank">Getting started</a></li> 
   <li><a href="https://github.com/piotr-kalanski/spark-local#examples" target="_blank">Examples</a></li> 
   <li><a href="https://github.com/piotr-kalanski/spark-local#io-operations" target="_blank">IO operations</a> 
    <ul> 
     <li><a href="https://github.com/piotr-kalanski/spark-local#supported-formats" target="_blank">Supported formats</a></li> 
     <li><a href="https://github.com/piotr-kalanski/spark-local#data-model-versioning" target="_blank">Data model versioning</a></li> 
     <li><a href="https://github.com/piotr-kalanski/spark-local#column-mapping" target="_blank">Column mapping</a></li> 
    </ul> </li> 
   <li><a href="https://github.com/piotr-kalanski/spark-local#aggregations" target="_blank">Aggregations</a></li> 
   <li><a href="https://github.com/piotr-kalanski/spark-local#supported-spark-versions" target="_blank">Supported Spark versions</a></li> 
   <li><a href="https://github.com/piotr-kalanski/spark-local/blob/master/doc/SupportedOperations.md" target="_blank">Supported Spark operations</a></li> 
   <li><a href="https://github.com/piotr-kalanski/spark-local/blob/master/benchmarks/Benchmarks.md" target="_blank">Benchmarks</a></li> 
   <li><a href="https://github.com/piotr-kalanski/spark-local/blob/master/CONTRIBUTING.md" target="_blank">Contributing</a></li> 
  </ul> 
  <h1><a href="https://github.com/piotr-kalanski/spark-local#goals" aria-hidden="true" class="anchor" id="user-content-goals" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Goals</h1> 
  <ul> 
   <li>Speed up unit testing for Spark applications</li> 
   <li>Enable switching between Spark execution engine and Scala collections depending on use case, especially size of data without changing implementation</li> 
  </ul> 
  <h1><a href="https://github.com/piotr-kalanski/spark-local#getting-started" aria-hidden="true" class="anchor" id="user-content-getting-started" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Getting started</h1> 
  <h2><a href="https://github.com/piotr-kalanski/spark-local#spark-211" aria-hidden="true" class="anchor" id="user-content-spark-211" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Spark 2.1.1</h2> 
  <p>Include dependency:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-s"><span class="pl-pds">"</span>com.github.piotr-kalanski<span class="pl-pds">"</span></span> <span class="pl-k">%</span> <span class="pl-s"><span class="pl-pds">"</span>spark-local_2.1.1_2.11<span class="pl-pds">"</span></span> <span class="pl-k">%</span> <span class="pl-s"><span class="pl-pds">"</span>0.6.0<span class="pl-pds">"</span></span></pre>
  </div> 
  <p>or</p> 
  <div class="highlight highlight-text-xml">
   <pre>&lt;<span class="pl-ent">dependency</span>&gt;
    &lt;<span class="pl-ent">groupId</span>&gt;com.github.piotr-kalanski&lt;/<span class="pl-ent">groupId</span>&gt;
    &lt;<span class="pl-ent">artifactId</span>&gt;spark-local_2.1.1_2.11&lt;/<span class="pl-ent">artifactId</span>&gt;
    &lt;<span class="pl-ent">version</span>&gt;0.6.0&lt;/<span class="pl-ent">version</span>&gt;
&lt;/<span class="pl-ent">dependency</span>&gt;</pre>
  </div> 
  <h2><a href="https://github.com/piotr-kalanski/spark-local#spark-210" aria-hidden="true" class="anchor" id="user-content-spark-210" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Spark 2.1.0</h2> 
  <p>Include dependency:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-s"><span class="pl-pds">"</span>com.github.piotr-kalanski<span class="pl-pds">"</span></span> <span class="pl-k">%</span> <span class="pl-s"><span class="pl-pds">"</span>spark-local_2.1.0_2.11<span class="pl-pds">"</span></span> <span class="pl-k">%</span> <span class="pl-s"><span class="pl-pds">"</span>0.6.0<span class="pl-pds">"</span></span></pre>
  </div> 
  <p>or</p> 
  <div class="highlight highlight-text-xml">
   <pre>&lt;<span class="pl-ent">dependency</span>&gt;
    &lt;<span class="pl-ent">groupId</span>&gt;com.github.piotr-kalanski&lt;/<span class="pl-ent">groupId</span>&gt;
    &lt;<span class="pl-ent">artifactId</span>&gt;spark-local_2.1.0_2.11&lt;/<span class="pl-ent">artifactId</span>&gt;
    &lt;<span class="pl-ent">version</span>&gt;0.6.0&lt;/<span class="pl-ent">version</span>&gt;
&lt;/<span class="pl-ent">dependency</span>&gt;</pre>
  </div> 
  <h1><a href="https://github.com/piotr-kalanski/spark-local#examples" aria-hidden="true" class="anchor" id="user-content-examples" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Examples</h1> 
  <h2><a href="https://github.com/piotr-kalanski/spark-local#creating-session" aria-hidden="true" class="anchor" id="user-content-creating-session" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Creating Session</h2> 
  <p>Entry point for library is session object which is similar to SparkSession object from Apache Spark.</p> 
  <p>Process of creating Session is also similar to Apache Spark.</p> 
  <p>When creating Session object you can choose between different execution engines. Currently supported:</p> 
  <ul> 
   <li>Spark - wrapper on Spark, which can be used at production data volumes</li> 
   <li>ScalaEager - implementation based on Scala collection with eager transformations, which makes it fast for unit testing</li> 
   <li>ScalaLazy - implementation based on Scala collection with lazy transformations, dedicated for working with small/mid size data</li> 
   <li>ScalaParallel - implementation based on Scala parallel collection with eager transformations</li> 
   <li>ScalaParallelLazy - implementation based on Scala parallel collection with lazy transformations</li> 
  </ul> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">import</span> <span class="pl-v">com.datawizards.sparklocal.session.ExecutionEngine.</span><span class="pl-v">ExecutionEngine</span>
<span class="pl-k">import</span> <span class="pl-v">com.datawizards.sparklocal.session.</span>{<span class="pl-v">ExecutionEngine</span>, <span class="pl-v">SparkSessionAPI</span>}

<span class="pl-c"><span class="pl-c">//</span> just change this value to start using different execution engine</span>
<span class="pl-k">val</span> <span class="pl-en">engine</span> <span class="pl-k">=</span> <span class="pl-en">ExecutionEngine</span>.<span class="pl-en">ScalaEager</span>

<span class="pl-k">val</span> <span class="pl-en">session</span> <span class="pl-k">=</span> <span class="pl-en">SparkSessionAPI</span>
      .builder(engine)
      .master(<span class="pl-s"><span class="pl-pds">"</span>local<span class="pl-pds">"</span></span>)
      .getOrCreate()

<span class="pl-k">val</span> <span class="pl-en">ds</span> <span class="pl-k">=</span> session.read[<span class="pl-en">Person</span>](<span class="pl-en">CSVDataStore</span>(file))</pre>
  </div> 
  <h2><a href="https://github.com/piotr-kalanski/spark-local#rdd-api" aria-hidden="true" class="anchor" id="user-content-rdd-api" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>RDD API</h2> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">import</span> <span class="pl-v">com.datawizards.sparklocal.rdd.</span><span class="pl-v">RDDAPI</span>
<span class="pl-k">import</span> <span class="pl-v">org.apache.spark.sql.</span><span class="pl-v">SparkSession</span>

<span class="pl-k">object</span> <span class="pl-en">ExampleRDD1</span> {

  <span class="pl-k">def</span> <span class="pl-en">main</span>(<span class="pl-v">args</span>: <span class="pl-en">Array</span>[<span class="pl-k">String</span>])<span class="pl-k">:</span> <span class="pl-k">Unit</span> <span class="pl-k">=</span> {
    <span class="pl-k">val</span> <span class="pl-en">spark</span> <span class="pl-k">=</span> <span class="pl-en">SparkSession</span>.builder().master(<span class="pl-s"><span class="pl-pds">"</span>local<span class="pl-pds">"</span></span>).getOrCreate()

    <span class="pl-k">val</span> <span class="pl-en">data</span> <span class="pl-k">=</span> <span class="pl-en">Seq</span>(<span class="pl-c1">1</span>,<span class="pl-c1">2</span>,<span class="pl-c1">3</span>)
    <span class="pl-k">val</span> <span class="pl-en">rdd</span> <span class="pl-k">=</span> spark.sparkContext.parallelize(data)

    assertEquals(
      calculateSum(<span class="pl-en">RDDAPI</span>(data)),
      calculateSum(<span class="pl-en">RDDAPI</span>(rdd))
    )

    assertEquals(
      calculateSumOfSquares(<span class="pl-en">RDDAPI</span>(data)),
      calculateSumOfSquares(<span class="pl-en">RDDAPI</span>(rdd))
    )

  }

  <span class="pl-k">def</span> <span class="pl-en">assertEquals</span>[<span class="pl-en">T</span>](r1<span class="pl-k">:</span><span class="pl-en">T</span>, r2<span class="pl-k">:</span><span class="pl-en">T</span>)<span class="pl-k">:</span> <span class="pl-k">Unit</span> <span class="pl-k">=</span> {
    println(r1)
    assert(r1 <span class="pl-k">==</span> r2)
  }

  <span class="pl-k">def</span> <span class="pl-en">calculateSum</span>(<span class="pl-v">ds</span>: <span class="pl-en">RDDAPI</span>[<span class="pl-k">Int</span>])<span class="pl-k">:</span> <span class="pl-k">Int</span> <span class="pl-k">=</span> ds.reduce(_ <span class="pl-k">+</span> _)
  <span class="pl-k">def</span> <span class="pl-en">calculateSumOfSquares</span>(<span class="pl-v">ds</span>: <span class="pl-en">RDDAPI</span>[<span class="pl-k">Int</span>])<span class="pl-k">:</span> <span class="pl-k">Int</span> <span class="pl-k">=</span> ds.map(x<span class="pl-k">=&gt;</span>x<span class="pl-k">*</span>x).reduce(_ <span class="pl-k">+</span> _)

}</pre>
  </div> 
  <h2><a href="https://github.com/piotr-kalanski/spark-local#dataset-api" aria-hidden="true" class="anchor" id="user-content-dataset-api" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Dataset API</h2> 
  <h3><a href="https://github.com/piotr-kalanski/spark-local#simple-example" aria-hidden="true" class="anchor" id="user-content-simple-example" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Simple example</h3> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">import</span> <span class="pl-v">com.datawizards.sparklocal.dataset.</span><span class="pl-v">DataSetAPI</span>
<span class="pl-k">import</span> <span class="pl-v">org.apache.spark.sql.</span><span class="pl-v">SparkSession</span>

<span class="pl-k">object</span> <span class="pl-en">ExampleDataset1</span> {

  <span class="pl-k">def</span> <span class="pl-en">main</span>(<span class="pl-v">args</span>: <span class="pl-en">Array</span>[<span class="pl-k">String</span>])<span class="pl-k">:</span> <span class="pl-k">Unit</span> <span class="pl-k">=</span> {
    <span class="pl-k">val</span> <span class="pl-en">spark</span> <span class="pl-k">=</span> <span class="pl-en">SparkSession</span>.builder().master(<span class="pl-s"><span class="pl-pds">"</span>local<span class="pl-pds">"</span></span>).getOrCreate()
    <span class="pl-k">import</span> <span class="pl-v">spark.implicits.</span><span class="pl-v">_</span>

    <span class="pl-k">val</span> <span class="pl-en">data</span> <span class="pl-k">=</span> <span class="pl-en">Seq</span>(<span class="pl-c1">1</span>,<span class="pl-c1">2</span>,<span class="pl-c1">3</span>)
    <span class="pl-k">val</span> <span class="pl-en">ds</span> <span class="pl-k">=</span> data.toDS()

    assertEquals(
      calculateSum(<span class="pl-en">DataSetAPI</span>(data)),
      calculateSum(<span class="pl-en">DataSetAPI</span>(ds))
    )

    assertEquals(
      calculateSumOfSquares(<span class="pl-en">DataSetAPI</span>(data)),
      calculateSumOfSquares(<span class="pl-en">DataSetAPI</span>(ds))
    )

  }

  <span class="pl-k">def</span> <span class="pl-en">assertEquals</span>[<span class="pl-en">T</span>](r1<span class="pl-k">:</span><span class="pl-en">T</span>, r2<span class="pl-k">:</span><span class="pl-en">T</span>)<span class="pl-k">:</span> <span class="pl-k">Unit</span> <span class="pl-k">=</span> {
    println(r1)
    assert(r1 <span class="pl-k">==</span> r2)
  }

  <span class="pl-k">def</span> <span class="pl-en">calculateSum</span>(<span class="pl-v">ds</span>: <span class="pl-en">DataSetAPI</span>[<span class="pl-k">Int</span>])<span class="pl-k">:</span> <span class="pl-k">Int</span> <span class="pl-k">=</span> ds.reduce(_ <span class="pl-k">+</span> _)
  <span class="pl-k">def</span> <span class="pl-en">calculateSumOfSquares</span>(<span class="pl-v">ds</span>: <span class="pl-en">DataSetAPI</span>[<span class="pl-k">Int</span>])<span class="pl-k">:</span> <span class="pl-k">Int</span> <span class="pl-k">=</span> ds.map(x<span class="pl-k">=&gt;</span>x<span class="pl-k">*</span>x).reduce(_ <span class="pl-k">+</span> _)

}</pre>
  </div> 
  <h3><a href="https://github.com/piotr-kalanski/spark-local#example-report" aria-hidden="true" class="anchor" id="user-content-example-report" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Example report</h3> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">case</span> <span class="pl-k">class</span> <span class="pl-en">Person</span>(<span class="pl-v">id</span>: <span class="pl-k">Int</span>, <span class="pl-v">name</span>: <span class="pl-k">String</span>, <span class="pl-v">gender</span>: <span class="pl-k">String</span>)
<span class="pl-k">case</span> <span class="pl-k">class</span> <span class="pl-en">WorkExperience</span>(<span class="pl-v">personId</span>: <span class="pl-k">Int</span>, <span class="pl-v">year</span>: <span class="pl-k">Int</span>, <span class="pl-v">title</span>: <span class="pl-k">String</span>)
<span class="pl-k">case</span> <span class="pl-k">class</span> <span class="pl-en">HRReport</span>(<span class="pl-v">year</span>: <span class="pl-k">Int</span>, <span class="pl-v">title</span>: <span class="pl-k">String</span>, <span class="pl-v">gender</span>: <span class="pl-k">String</span>, <span class="pl-v">count</span>: <span class="pl-k">Int</span>)

<span class="pl-k">object</span> <span class="pl-en">ExampleHRReport</span> {

  <span class="pl-k">def</span> <span class="pl-en">main</span>(<span class="pl-v">args</span>: <span class="pl-en">Array</span>[<span class="pl-k">String</span>])<span class="pl-k">:</span> <span class="pl-k">Unit</span> <span class="pl-k">=</span> {
    <span class="pl-k">val</span> <span class="pl-en">spark</span> <span class="pl-k">=</span> <span class="pl-en">SparkSession</span>.builder().master(<span class="pl-s"><span class="pl-pds">"</span>local<span class="pl-pds">"</span></span>).getOrCreate()
    <span class="pl-k">import</span> <span class="pl-v">spark.implicits.</span><span class="pl-v">_</span>

    <span class="pl-k">val</span> <span class="pl-en">people</span> <span class="pl-k">=</span> <span class="pl-en">SampleData</span>.people
    <span class="pl-k">val</span> <span class="pl-en">peopleDs</span> <span class="pl-k">=</span> people.toDS()
    <span class="pl-k">val</span> <span class="pl-en">experience</span> <span class="pl-k">=</span> <span class="pl-en">SampleData</span>.experience
    <span class="pl-k">val</span> <span class="pl-en">experienceDs</span> <span class="pl-k">=</span> experience.toDS()


    calculateReport(<span class="pl-en">DataSetAPI</span>(people), <span class="pl-en">DataSetAPI</span>(experience))
    calculateReport(<span class="pl-en">DataSetAPI</span>(peopleDs), <span class="pl-en">DataSetAPI</span>(experienceDs))
  }

  <span class="pl-k">def</span> <span class="pl-en">calculateReport</span>(<span class="pl-v">people</span>: <span class="pl-en">DataSetAPI</span>[<span class="pl-en">Person</span>], <span class="pl-v">workExperience</span>: <span class="pl-en">DataSetAPI</span>[<span class="pl-en">WorkExperience</span>])<span class="pl-k">:</span> <span class="pl-en">DataSetAPI</span>[<span class="pl-en">HRReport</span>] <span class="pl-k">=</span> {
    workExperience
      .join(people)(_.personId, _.id)
      .groupByKey(wp <span class="pl-k">=&gt;</span> (wp._1.year, wp._1.title, wp._2.gender))
      .mapGroups{<span class="pl-k">case</span> ((year, title, gender), vals) <span class="pl-k">=&gt;</span> <span class="pl-en">HRReport</span>(year, title, gender, vals.size)}
  }

}</pre>
  </div> 
  <h1><a href="https://github.com/piotr-kalanski/spark-local#io-operations" aria-hidden="true" class="anchor" id="user-content-io-operations" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>IO operations</h1> 
  <p>Library provides dedicated API for input/output operations with implementation for Spark and Scala collections.</p> 
  <h2><a href="https://github.com/piotr-kalanski/spark-local#supported-formats" aria-hidden="true" class="anchor" id="user-content-supported-formats" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Supported formats</h2> 
  <p>Supported formats:</p> 
  <ul> 
   <li>CSV</li> 
   <li>JSON</li> 
   <li>Parquet</li> 
   <li>Avro</li> 
   <li>Hive</li> 
   <li>JDBC 
    <ul> 
     <li>H2</li> 
     <li>MySQL</li> 
    </ul> </li> 
   <li>Elasticsearch</li> 
  </ul> 
  <h3><a href="https://github.com/piotr-kalanski/spark-local#csv" aria-hidden="true" class="anchor" id="user-content-csv" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>CSV</h3> 
  <h4><a href="https://github.com/piotr-kalanski/spark-local#read-csv-file" aria-hidden="true" class="anchor" id="user-content-read-csv-file" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Read CSV file</h4> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">val</span> <span class="pl-en">reader</span><span class="pl-k">:</span> <span class="pl-en">Reader</span> <span class="pl-k">=</span> <span class="pl-en">ReaderScalaImpl</span> <span class="pl-c"><span class="pl-c">//</span> Scala implementation</span>
<span class="pl-c"><span class="pl-c">//</span>val reader: Reader = ReaderSparkImpl // Spark implementation</span>

reader.read[<span class="pl-en">Person</span>](
    <span class="pl-en">CSVDataStore</span>(
        path <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>people.csv<span class="pl-pds">"</span></span>,
        delimiter <span class="pl-k">=</span> <span class="pl-c1">';'</span>,
        header <span class="pl-k">=</span> <span class="pl-c1">false</span>,
        columns <span class="pl-k">=</span> <span class="pl-en">Seq</span>(<span class="pl-s"><span class="pl-pds">"</span>name<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>age<span class="pl-pds">"</span></span>)
    )
)</pre>
  </div> 
  <h4><a href="https://github.com/piotr-kalanski/spark-local#write-to-csv-file" aria-hidden="true" class="anchor" id="user-content-write-to-csv-file" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Write to CSV file</h4> 
  <div class="highlight highlight-source-scala">
   <pre>ds.write(<span class="pl-en">CSVDataStore</span>(file), <span class="pl-en">SaveMode</span>.<span class="pl-en">Overwrite</span>)</pre>
  </div> 
  <h3><a href="https://github.com/piotr-kalanski/spark-local#json" aria-hidden="true" class="anchor" id="user-content-json" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>JSON</h3> 
  <h4><a href="https://github.com/piotr-kalanski/spark-local#read-json-file" aria-hidden="true" class="anchor" id="user-content-read-json-file" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Read JSON file</h4> 
  <div class="highlight highlight-source-scala">
   <pre>reader.read[<span class="pl-en">Person</span>](<span class="pl-en">JsonDataStore</span>(<span class="pl-s"><span class="pl-pds">"</span>people.json<span class="pl-pds">"</span></span>))</pre>
  </div> 
  <h4><a href="https://github.com/piotr-kalanski/spark-local#write-to-json-file" aria-hidden="true" class="anchor" id="user-content-write-to-json-file" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Write to JSON file</h4> 
  <div class="highlight highlight-source-scala">
   <pre>ds.write(<span class="pl-en">JsonDataStore</span>(<span class="pl-s"><span class="pl-pds">"</span>people.json<span class="pl-pds">"</span></span>), <span class="pl-en">SaveMode</span>.<span class="pl-en">Overwrite</span>)</pre>
  </div> 
  <h3><a href="https://github.com/piotr-kalanski/spark-local#avro" aria-hidden="true" class="anchor" id="user-content-avro" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Avro</h3> 
  <p>Current implementation produces different binary files for Spark and Scala. Spark by default compress files with snappy and spark-local implementation is based on: <a href="https://github.com/sksamuel/avro4s" target="_blank">https://github.com/sksamuel/avro4s</a>, which saves data without compression.</p> 
  <h4><a href="https://github.com/piotr-kalanski/spark-local#read-avro-file" aria-hidden="true" class="anchor" id="user-content-read-avro-file" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Read Avro file</h4> 
  <div class="highlight highlight-source-scala">
   <pre>reader.read[<span class="pl-en">Person</span>](<span class="pl-en">AvroDataStore</span>(<span class="pl-s"><span class="pl-pds">"</span>people.avro<span class="pl-pds">"</span></span>))</pre>
  </div> 
  <h4><a href="https://github.com/piotr-kalanski/spark-local#write-to-avro-file" aria-hidden="true" class="anchor" id="user-content-write-to-avro-file" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Write to Avro file</h4> 
  <div class="highlight highlight-source-scala">
   <pre>ds.write(<span class="pl-en">AvroDataStore</span>(<span class="pl-s"><span class="pl-pds">"</span>people.avro<span class="pl-pds">"</span></span>), <span class="pl-en">SaveMode</span>.<span class="pl-en">Overwrite</span>)</pre>
  </div> 
  <h3><a href="https://github.com/piotr-kalanski/spark-local#parquet" aria-hidden="true" class="anchor" id="user-content-parquet" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Parquet</h3> 
  <h4><a href="https://github.com/piotr-kalanski/spark-local#read-parquet-file" aria-hidden="true" class="anchor" id="user-content-read-parquet-file" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Read Parquet file</h4> 
  <div class="highlight highlight-source-scala">
   <pre>reader.read[<span class="pl-en">Person</span>](<span class="pl-en">ParquetDataStore</span>(<span class="pl-s"><span class="pl-pds">"</span>people.parquet<span class="pl-pds">"</span></span>))</pre>
  </div> 
  <h4><a href="https://github.com/piotr-kalanski/spark-local#write-to-parquet-file" aria-hidden="true" class="anchor" id="user-content-write-to-parquet-file" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Write to Parquet file</h4> 
  <div class="highlight highlight-source-scala">
   <pre>ds.write(<span class="pl-en">ParquetDataStore</span>(<span class="pl-s"><span class="pl-pds">"</span>people.parquet<span class="pl-pds">"</span></span>), <span class="pl-en">SaveMode</span>.<span class="pl-en">Overwrite</span>)</pre>
  </div> 
  <h3><a href="https://github.com/piotr-kalanski/spark-local#hive" aria-hidden="true" class="anchor" id="user-content-hive" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Hive</h3> 
  <h4><a href="https://github.com/piotr-kalanski/spark-local#read-hive-table" aria-hidden="true" class="anchor" id="user-content-read-hive-table" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Read Hive table</h4> 
  <div class="highlight highlight-source-scala">
   <pre>reader.read[<span class="pl-en">Person</span>](<span class="pl-en">HiveDataStore</span>(<span class="pl-s"><span class="pl-pds">"</span>db<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>table<span class="pl-pds">"</span></span>))</pre>
  </div> 
  <h4><a href="https://github.com/piotr-kalanski/spark-local#write-to-hive-table" aria-hidden="true" class="anchor" id="user-content-write-to-hive-table" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Write to Hive table</h4> 
  <div class="highlight highlight-source-scala">
   <pre>ds.write(<span class="pl-en">HiveDataStore</span>(<span class="pl-s"><span class="pl-pds">"</span>db<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>table<span class="pl-pds">"</span></span>), <span class="pl-en">SaveMode</span>.<span class="pl-en">Overwrite</span>)</pre>
  </div> 
  <h3><a href="https://github.com/piotr-kalanski/spark-local#jdbc" aria-hidden="true" class="anchor" id="user-content-jdbc" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>JDBC</h3> 
  <h4><a href="https://github.com/piotr-kalanski/spark-local#read-jdbc-table" aria-hidden="true" class="anchor" id="user-content-read-jdbc-table" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Read JDBC table</h4> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">val</span> <span class="pl-en">database</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>public<span class="pl-pds">"</span></span>
<span class="pl-k">val</span> <span class="pl-en">table</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>people<span class="pl-pds">"</span></span>
<span class="pl-k">val</span> <span class="pl-en">properties</span> <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-en">java.util.Properties</span>()
reader.read[<span class="pl-en">Person</span>](<span class="pl-en">H2DataStore</span>(connectionString, database, table, properties))</pre>
  </div> 
  <h4><a href="https://github.com/piotr-kalanski/spark-local#write-to-jdbc-table" aria-hidden="true" class="anchor" id="user-content-write-to-jdbc-table" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Write to JDBC table</h4> 
  <div class="highlight highlight-source-scala">
   <pre>ds.write(<span class="pl-en">H2DataStore</span>(connectionString, database, table, properties), <span class="pl-en">SaveMode</span>.<span class="pl-en">Append</span>)</pre>
  </div> 
  <h3><a href="https://github.com/piotr-kalanski/spark-local#elasticsearch" aria-hidden="true" class="anchor" id="user-content-elasticsearch" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Elasticsearch</h3> 
  <h4><a href="https://github.com/piotr-kalanski/spark-local#write-to-elasticsearch-index" aria-hidden="true" class="anchor" id="user-content-write-to-elasticsearch-index" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Write to Elasticsearch index</h4> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">val</span> <span class="pl-en">indexName</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>people<span class="pl-pds">"</span></span>
<span class="pl-k">val</span> <span class="pl-en">typeName</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>person<span class="pl-pds">"</span></span>
ds.write(<span class="pl-en">ElasticsearchSimpleIndexDataStore</span>(<span class="pl-s"><span class="pl-pds">"</span>localhost<span class="pl-pds">"</span></span>, indexName, typeName), <span class="pl-en">SaveMode</span>.<span class="pl-en">Append</span>)</pre>
  </div> 
  <h2><a href="https://github.com/piotr-kalanski/spark-local#data-model-versioning" aria-hidden="true" class="anchor" id="user-content-data-model-versioning" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Data model versioning</h2> 
  <p>Library supports reading data using old and new version of data model.</p> 
  <p>Reading with old version of data model is straightforward, just existing fields will be read. On other hand, when reading with new version of data model, new columns should be <code>Option</code> type and value <code>None</code> is assigned to those fields.</p> 
  <p><strong>Example</strong></p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">import</span> <span class="pl-v">com.datawizards.sparklocal.datastore.</span><span class="pl-v">CSVDataStore</span>
<span class="pl-k">import</span> <span class="pl-v">com.datawizards.sparklocal.session.</span>{<span class="pl-v">ExecutionEngine</span>, <span class="pl-v">SparkSessionAPI</span>}
<span class="pl-k">import</span> <span class="pl-v">org.apache.spark.sql.</span><span class="pl-v">SaveMode</span>

<span class="pl-k">case</span> <span class="pl-k">class</span> <span class="pl-en">Person</span>(<span class="pl-v">name</span>: <span class="pl-k">String</span>, <span class="pl-v">age</span>: <span class="pl-k">Int</span>)
<span class="pl-k">case</span> <span class="pl-k">class</span> <span class="pl-en">PersonV2</span>(<span class="pl-v">name</span>: <span class="pl-k">String</span>, <span class="pl-v">age</span>: <span class="pl-k">Int</span>, <span class="pl-v">title</span>: <span class="pl-en">Option</span>[<span class="pl-k">String</span>])
<span class="pl-k">case</span> <span class="pl-k">class</span> <span class="pl-en">PersonV3</span>(<span class="pl-v">name</span>: <span class="pl-k">String</span>, <span class="pl-v">age</span>: <span class="pl-k">Int</span>, <span class="pl-v">title</span>: <span class="pl-en">Option</span>[<span class="pl-k">String</span>], <span class="pl-v">salary</span>: <span class="pl-en">Option</span>[<span class="pl-k">Long</span>])

<span class="pl-k">val</span> <span class="pl-en">session</span> <span class="pl-k">=</span> <span class="pl-en">SparkSessionAPI</span>
      .builder(<span class="pl-en">ExecutionEngine</span>.<span class="pl-en">ScalaEager</span>)
      .master(<span class="pl-s"><span class="pl-pds">"</span>local<span class="pl-pds">"</span></span>)
      .getOrCreate()

<span class="pl-k">import</span> <span class="pl-v">session.implicits.</span><span class="pl-v">_</span>

<span class="pl-k">val</span> <span class="pl-en">peopleV2</span> <span class="pl-k">=</span> session.createDataset(<span class="pl-en">Seq</span>(
    <span class="pl-en">PersonV2</span>(<span class="pl-s"><span class="pl-pds">"</span>p1<span class="pl-pds">"</span></span>, <span class="pl-c1">10</span>, <span class="pl-en">Some</span>(<span class="pl-s"><span class="pl-pds">"</span>Mr<span class="pl-pds">"</span></span>)),
    <span class="pl-en">PersonV2</span>(<span class="pl-s"><span class="pl-pds">"</span>p2<span class="pl-pds">"</span></span>, <span class="pl-c1">20</span>, <span class="pl-en">Some</span>(<span class="pl-s"><span class="pl-pds">"</span>Ms<span class="pl-pds">"</span></span>)),
    <span class="pl-en">PersonV2</span>(<span class="pl-s"><span class="pl-pds">"</span>p3<span class="pl-pds">"</span></span>, <span class="pl-c1">30</span>, <span class="pl-c1">None</span>),
    <span class="pl-en">PersonV2</span>(<span class="pl-s"><span class="pl-pds">"</span>p4<span class="pl-pds">"</span></span>, <span class="pl-c1">40</span>, <span class="pl-en">Some</span>(<span class="pl-s"><span class="pl-pds">"</span>Mr<span class="pl-pds">"</span></span>))
))

<span class="pl-k">val</span> <span class="pl-en">dataStore</span> <span class="pl-k">=</span> <span class="pl-en">CSVDataStore</span>(<span class="pl-s"><span class="pl-pds">"</span>people_v2.csv<span class="pl-pds">"</span></span>)
peopleV2.write(dataStore, <span class="pl-en">SaveMode</span>.<span class="pl-en">Overwrite</span>)

<span class="pl-c"><span class="pl-c">//</span> Read old version:</span>
<span class="pl-k">val</span> <span class="pl-en">peopleV1</span> <span class="pl-k">=</span> session.read[<span class="pl-en">Person</span>](dataStore)

<span class="pl-c"><span class="pl-c">//</span> Read new version:</span>
<span class="pl-k">val</span> <span class="pl-en">peopleV3</span> <span class="pl-k">=</span> session.read[<span class="pl-en">PersonV3</span>](dataStore)

peopleV1.show()
peopleV3.show()</pre>
  </div> 
  <pre><code>+----+---+
|name|age|
+----+---+
|p1  |10 |
|p2  |20 |
|p3  |30 |
|p4  |40 |
+----+---+

+----+---+-----+------+
|name|age|title|salary|
+----+---+-----+------+
|p1  |10 |Mr   |      |
|p2  |20 |Ms   |      |
|p3  |30 |     |      |
|p4  |40 |Mr   |      |
+----+---+-----+------+
</code></pre> 
  <h2><a href="https://github.com/piotr-kalanski/spark-local#column-mapping" aria-hidden="true" class="anchor" id="user-content-column-mapping" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Column mapping</h2> 
  <p>Library supports changing name of fields when writing and reading data.</p> 
  <p>Mapping is provided using <code>column</code> annotation from project: <a href="https://github.com/piotr-kalanski/data-model-generator" target="_blank">https://github.com/piotr-kalanski/data-model-generator</a>.</p> 
  <p><strong>Example</strong></p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">import</span> <span class="pl-v">com.datawizards.dmg.annotations.</span><span class="pl-v">column</span>
<span class="pl-k">import</span> <span class="pl-v">com.datawizards.sparklocal.dataset.io.</span><span class="pl-v">ModelDialects</span>
<span class="pl-k">import</span> <span class="pl-v">com.datawizards.sparklocal.datastore.</span><span class="pl-v">JsonDataStore</span>
<span class="pl-k">import</span> <span class="pl-v">com.datawizards.sparklocal.session.</span>{<span class="pl-v">ExecutionEngine</span>, <span class="pl-v">SparkSessionAPI</span>}
<span class="pl-k">import</span> <span class="pl-v">org.apache.spark.sql.</span><span class="pl-v">SaveMode</span>

<span class="pl-k">case</span> <span class="pl-k">class</span> <span class="pl-en">PersonWithMapping</span>(
    <span class="pl-k">@</span>column(<span class="pl-s"><span class="pl-pds">"</span>personName<span class="pl-pds">"</span></span>, dialect <span class="pl-k">=</span> <span class="pl-en">ModelDialects</span>.<span class="pl-en">JSON</span>)
    <span class="pl-v">name</span>: <span class="pl-k">String</span>,
    <span class="pl-k">@</span>column(<span class="pl-s"><span class="pl-pds">"</span>personAge<span class="pl-pds">"</span></span>, dialect <span class="pl-k">=</span> <span class="pl-en">ModelDialects</span>.<span class="pl-en">JSON</span>)
    <span class="pl-v">age</span>: <span class="pl-k">Int</span>
)

<span class="pl-k">val</span> <span class="pl-en">session</span> <span class="pl-k">=</span> <span class="pl-en">SparkSessionAPI</span>
      .builder(<span class="pl-en">ExecutionEngine</span>.<span class="pl-en">ScalaEager</span>)
      .master(<span class="pl-s"><span class="pl-pds">"</span>local<span class="pl-pds">"</span></span>)
      .getOrCreate()

<span class="pl-k">import</span> <span class="pl-v">session.implicits.</span><span class="pl-v">_</span>

<span class="pl-k">val</span> <span class="pl-en">people</span> <span class="pl-k">=</span> session.createDataset(<span class="pl-en">Seq</span>(
    <span class="pl-en">PersonWithMapping</span>(<span class="pl-s"><span class="pl-pds">"</span>p1<span class="pl-pds">"</span></span>, <span class="pl-c1">10</span>),
    <span class="pl-en">PersonWithMapping</span>(<span class="pl-s"><span class="pl-pds">"</span>p2<span class="pl-pds">"</span></span>, <span class="pl-c1">20</span>),
    <span class="pl-en">PersonWithMapping</span>(<span class="pl-s"><span class="pl-pds">"</span>p3<span class="pl-pds">"</span></span>, <span class="pl-c1">30</span>),
    <span class="pl-en">PersonWithMapping</span>(<span class="pl-s"><span class="pl-pds">"</span>p4<span class="pl-pds">"</span></span>, <span class="pl-c1">40</span>)
))

<span class="pl-k">val</span> <span class="pl-en">dataStore</span> <span class="pl-k">=</span> <span class="pl-en">JsonDataStore</span>(<span class="pl-s"><span class="pl-pds">"</span>people_mapping.json<span class="pl-pds">"</span></span>)
people.write(dataStore, <span class="pl-en">SaveMode</span>.<span class="pl-en">Overwrite</span>)
</pre>
  </div> 
  <p>Name of fields in JSON file are consistent with column names provided in annotations:</p> 
  <div class="highlight highlight-source-json">
   <pre>{<span class="pl-s"><span class="pl-pds">"</span>personName<span class="pl-pds">"</span></span>:<span class="pl-s"><span class="pl-pds">"</span>p1<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>personAge<span class="pl-pds">"</span></span>:<span class="pl-c1">10</span>}
{<span class="pl-s"><span class="pl-pds">"</span>personName<span class="pl-pds">"</span></span>:<span class="pl-s"><span class="pl-pds">"</span>p2<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>personAge<span class="pl-pds">"</span></span>:<span class="pl-c1">20</span>}
{<span class="pl-s"><span class="pl-pds">"</span>personName<span class="pl-pds">"</span></span>:<span class="pl-s"><span class="pl-pds">"</span>p3<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>personAge<span class="pl-pds">"</span></span>:<span class="pl-c1">30</span>}
{<span class="pl-s"><span class="pl-pds">"</span>personName<span class="pl-pds">"</span></span>:<span class="pl-s"><span class="pl-pds">"</span>p4<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>personAge<span class="pl-pds">"</span></span>:<span class="pl-c1">40</span>}</pre>
  </div> 
  <p>Reading data:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">val</span> <span class="pl-en">people2</span> <span class="pl-k">=</span> session.read[<span class="pl-en">PersonWithMapping</span>](dataStore)
people2.show()</pre>
  </div> 
  <p>Names of columns are the same as case class fields:</p> 
  <pre><code>+----+---+
|name|age|
+----+---+
|p1  |10 |
|p2  |20 |
|p3  |30 |
|p4  |40 |
+----+---+
</code></pre> 
  <h1><a href="https://github.com/piotr-kalanski/spark-local#aggregations" aria-hidden="true" class="anchor" id="user-content-aggregations" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Aggregations</h1> 
  <p>Library provides custom type-safe API for aggregations.</p> 
  <p>Example operations:</p> 
  <div class="highlight highlight-source-scala">
   <pre><span class="pl-k">import</span> <span class="pl-v">com.datawizards.sparklocal.dataset.agg.</span><span class="pl-v">_</span>

ds
    .groupByKey(_.name)
    .agg(sum(_.age), count(), mean(_.age), max(_.age))</pre>
  </div> 
  <h1><a href="https://github.com/piotr-kalanski/spark-local#supported-spark-versions" aria-hidden="true" class="anchor" id="user-content-supported-spark-versions" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Supported Spark versions</h1> 
  <table> 
   <thead> 
    <tr> 
     <th>spark-local</th> 
     <th>Spark version</th> 
    </tr> 
   </thead> 
   <tbody> 
    <tr> 
     <td>0.7</td> 
     <td>2.1.1<br>2.1.0</td> 
    </tr> 
    <tr> 
     <td>0.6</td> 
     <td>2.1.1<br>2.1.0</td> 
    </tr> 
    <tr> 
     <td>0.5</td> 
     <td>2.1.0</td> 
    </tr> 
    <tr> 
     <td>0.4</td> 
     <td>2.1.0</td> 
    </tr> 
    <tr> 
     <td>0.3</td> 
     <td>2.1.0</td> 
    </tr> 
    <tr> 
     <td>0.2</td> 
     <td>2.1.0</td> 
    </tr> 
    <tr> 
     <td>0.1</td> 
     <td>2.1.0</td> 
    </tr>
   </tbody>
  </table> 
  <h1><a href="https://github.com/piotr-kalanski/spark-local#bugs" aria-hidden="true" class="anchor" id="user-content-bugs" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Bugs</h1> 
  <p>Please report any bugs to <a href="https://github.com/piotr-kalanski/spark-local/issues" target="_blank">spark-local Github issue tracker</a>.</p> 
  <h1><a href="https://github.com/piotr-kalanski/spark-local#continuous-integration" aria-hidden="true" class="anchor" id="user-content-continuous-integration" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Continuous Integration</h1> 
  <p><a href="https://travis-ci.org/piotr-kalanski/spark-local/builds" target="_blank">Build History</a></p> 
  <h1><a href="https://github.com/piotr-kalanski/spark-local#contact" aria-hidden="true" class="anchor" id="user-content-contact" target="_blank">
    <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewbox="0 0 16 16" width="16">
     <path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
    </svg></a>Contact</h1> 
  <p><a href="mailto:piotr.kalanski@gmail.com" target="_blank">piotr.kalanski@gmail.com</a></p> 
 </article>
</div>